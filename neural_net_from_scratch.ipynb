{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code represents a neural network with 3 layers with 3, 2 and 1 neurons respectively:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general layer vector can be written as:\n",
    "\n",
    "$$\\vec{a}^{[j]} = g(\\vec{a}^{[j-1]} . \\vec{w}_i^{[j]} + b_i^{[j]})$$\n",
    "for example for $=2$ and $j=1$:\n",
    "\n",
    "$$\\vec{a}^{[1]} = g(\\vec{a}^{[0]} . \\vec{w}_2^{[1]} + b_2^{[1]})$$\n",
    "\n",
    "The $W^{[j]}$ matrix has the dimension $(n_{u_{in}} \\times n_{u_{out}})$:\n",
    "\n",
    "- $W^{[1]}$: ($2 \\times 3$)\n",
    "- $W^{[2]}$: ($3 \\times 2$)\n",
    "- $W^{[3]}$: ($2 \\times 1$)\n",
    "\n",
    "$b$ has dimension $(n_{u_{out}}, )$, or\n",
    "\n",
    "- $b^{[1]}$: ($3,$)\n",
    "- $b^{[2]}$: ($2,$)\n",
    "- $b^{[3]}$: ($1,$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is 2 and the number of units/neurons is 3 for the first layer.\n",
      "The number of features is 3 and the number of units/neurons is 2 for the second layer.\n",
      "The number of features is 2 and the number of units/neurons is 1 for the third layer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83942385])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2])\n",
    "\n",
    "W1 = np.array([[1,-3,5],\n",
    "              [2,4,-6]])\n",
    "b1 = np.array([-1,1,2])\n",
    "mw1,nw1 = W1.shape\n",
    "print(f'The number of features is {mw1} and the number of units/neurons is {nw1} for the first layer.')\n",
    "\n",
    "W2 = np.array([[1,-3],\n",
    "              [2,4],\n",
    "              [5,1]])\n",
    "b2 = np.array([-1,1])\n",
    "mw2,nw2 = W2.shape\n",
    "print(f'The number of features is {mw2} and the number of units/neurons is {nw2} for the second layer.')\n",
    "\n",
    "W3 = np.array([[1],\n",
    "              [2]])\n",
    "b3 = np.array([-1])\n",
    "mw3,nw3 = W3.shape\n",
    "print(f'The number of features is {mw3} and the number of units/neurons is {nw3} for the third layer.')\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def dense(a_in, W, b):\n",
    "    \"\"\"\n",
    "    a_in: activation vector with shape (n, ), where n is the number of features\n",
    "    W: weights matrix with shape (n, u), where n is the number of features and u the number of units\n",
    "    b: bias with shape (u, )\n",
    "\n",
    "    Returns: a_out (u, )\n",
    "    \"\"\"\n",
    "    m,units = W.shape\n",
    "    a_out = np.zeros(units)\n",
    "    for i in range(units):\n",
    "        w = W[:,i]\n",
    "        z = np.dot(a_in, w) + b[i]\n",
    "        a_out[i] = sigmoid(z)\n",
    "    # print(a_out.shape)\n",
    "    return a_out\n",
    "\n",
    "def sequential(x,W1,b1,W2,b2,W3,b3):\n",
    "    a1 = dense(x, W1, b1)\n",
    "    a2 = dense(a1, W2, b2)\n",
    "    a3 = dense(a2, W3, b3)\n",
    "    return a3\n",
    "\n",
    "sequential(x,W1,b1,W2,b2,W3,b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x,W1,b1,W2,b2,W3,b3):\n",
    "    m,n = x.shape\n",
    "    probability = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        s = sequential(x[i],W1,b1,W2,b2,W3,b3)\n",
    "        probability[i] = float(s)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tf.keras.layers.Normalization(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0.87648605]\n",
      " [0.62976062]\n",
      " [0.84782889]]\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[0,0.1],\n",
    "                   [100.5,2],\n",
    "                   [-10,-1]])\n",
    "print(x_test.shape)\n",
    "xn_test = normal(x_test)\n",
    "\n",
    "predic = prediction(xn_test,W1,b1,W2,b2,W3,b3)\n",
    "print(predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "y = np.zeros(len(xn_test))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if predic[i] > 0.5:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using a vectorized way, with matrices: $\\textbf{A}$, $\\textbf{W}$, $\\textbf{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2],\n",
    "              [4,5],\n",
    "              [10,11]])\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def dense(A_in, n_out):\n",
    "    \"\"\"\n",
    "    A_in (ndarray (n, )): activation/data that goes in this layer\n",
    "    n_out (int):          number of neurons/units of next layer\n",
    "    A_out\n",
    "    \"\"\"\n",
    "    m,units = A_in.shape\n",
    "    W = np.random.random((units,n_out))\n",
    "    b = np.random.random((1,n_out))\n",
    "    Z = np.dot(A_in, W) + b\n",
    "    A_out = sigmoid(Z)\n",
    "    return A_out\n",
    "\n",
    "def sequential(X):\n",
    "    a1 = dense(X,3)\n",
    "    a2 = dense(a1,2)\n",
    "    a3 = dense(a2,1)\n",
    "    return a3\n",
    "\n",
    "def prediction(X_test):\n",
    "    m,n = X_test.shape\n",
    "    probability = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        s = sequential(X_test)[i]\n",
    "        probability[i] = float(s)\n",
    "    return probability\n",
    "\n",
    "x_test = np.array([[0,0.1],\n",
    "                   [100.5,2],\n",
    "                   [-10,-1]])\n",
    "                   \n",
    "normal = tf.keras.layers.Normalization(axis=-1)\n",
    "xn_test = normal(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "predic = prediction(xn_test)\n",
    "\n",
    "y = np.zeros(len(xn_test))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if predic[i] > 0.5:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "037335531d7621c1b1b0f2b1596a260ebe03ba48a827428118e6a4217105d671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
